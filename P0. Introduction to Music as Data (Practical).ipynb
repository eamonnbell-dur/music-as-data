{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903e35d8-c8bc-4b95-ba49-11afcdffdd5c",
   "metadata": {},
   "source": [
    "# P0. Introduction to Music as Data (Practical)\n",
    "\n",
    "Eamonn Bell \\<eamonn.bell@durham.ac.uk\\>  \n",
    "Department of Computer Science  \n",
    "Durham University\n",
    "\n",
    "Guest lecture for Master of Data Science (Digital Humanities) students  \n",
    "Digital Humanities: Practice and Theory (Heslin)  \n",
    "9a-11a, 1p-2p; November 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5316ac46-2fb4-44b7-b477-880e36ffe425",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Everyone should complete P0.T1 and attempt at least one of P0.T2.a, P0.T2.b, or P0.T2.c.\n",
    "\n",
    "At about 1:40 p.m. I'll invite some of you to share your visualisation with the class. To do this, please join the Zoom room (with your microphone muted or, ideally, without joining the audio part of the call!) and share your screen.\n",
    "\n",
    "If you are happy to do so, please download and email your attempts to me in the .ipynb format at <eamonn.bell@durham.ac.uk>. They will not be marked but they will help me improve this material for future courses on the same topic.\n",
    "\n",
    "### P0.T1. Create your own visualisation of your \n",
    "\n",
    "- Record your own audio file of you\n",
    "    - speaking, or\n",
    "    - humming, or\n",
    "    - singing, or\n",
    "    - clapping, or\n",
    "    - playing a musical instrument\n",
    "- Process it whatever way you like using simple arithemetic operations or more complicated `numpy` functions\n",
    "    - reduce it in volume, or\n",
    "    - reverse it, or\n",
    "    - clip it, or\n",
    "    - perform a rolling average on it, or\n",
    "    - trim it, or\n",
    "    - produce a spectrogram of it\n",
    "- Extract some features or segmentations using the onset and beat detection implementations in `librosa`\n",
    "    - Optionally, sonify these features and visualise the effect of this sonification, through the addition of further subplots.\n",
    "- Use `matplotlib` subplots to connect your visual representations of the the original recording and your processed/analysed version of it, in order to tell a story about the relationship between them.\n",
    "\n",
    "### P0.T2.a. @DLEveryFriday\n",
    "\n",
    "Every Friday since X, David Lynch has posted a video message.\n",
    "\n",
    "### P0.T2.a. Write your own onset detector\n",
    "\n",
    "- scoring function\n",
    "- parameter search\n",
    "\n",
    "### P0.T2.c. Text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15862d0e-2b93-4159-b7c1-83089cfb3c8a",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### Useful Python packages\n",
    "\n",
    "### Learning more\n",
    "\n",
    "- musicinformationretrieval.com\n",
    "- FMP\n",
    "- `librosa` documentationmaking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
