{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "903e35d8-c8bc-4b95-ba49-11afcdffdd5c",
   "metadata": {},
   "source": [
    "# P0. Introduction to Music as Data (Practical)\n",
    "\n",
    "Eamonn Bell \\<eamonn.bell@durham.ac.uk\\>  \n",
    "Department of Computer Science  \n",
    "Durham University\n",
    "\n",
    "Guest lecture for Master of Data Science (Digital Humanities) students  \n",
    "Digital Humanities: Practice and Theory (Heslin)  \n",
    "9a-11a, 1p-2p; November 28, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b9bb2-10ac-49c5-9d72-4e3452584e69",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Everyone should complete P0.T1 and attempt at least one of P0.T2.a, P0.T2.b, or P0.T2.c.\n",
    "\n",
    "At about 1:40 p.m. I'll invite some of you to share your visualisation with the class. To do this, please join the Zoom room (with your microphone muted or, ideally, without joining the audio part of the call!) and share your screen.\n",
    "\n",
    "If you are happy to do so, please download and email your attempts to me in the .ipynb format at <eamonn.bell@durham.ac.uk>. They will not be marked but they will help me improve this material for future courses on the same topic.\n",
    "\n",
    "If you need to install packages from PyPI or from Github in this notebook you can do so by adding a cell with the following format\n",
    "\n",
    "```\n",
    "!pip install PACKAGE_NAME\n",
    "```\n",
    "\n",
    "### P0.T1. Create your own visualisation of your own musical/sonic production\n",
    "\n",
    "- Record your own audio file of you\n",
    "    - speaking, or\n",
    "    - humming, or\n",
    "    - singing, or\n",
    "    - clapping, or\n",
    "    - playing a musical instrument\n",
    "- Process it whatever way you like using simple arithemetic operations or more complicated `numpy` functions\n",
    "    - reduce it in volume, or\n",
    "    - reverse it, or\n",
    "    - clip it, or\n",
    "    - perform a rolling average on it, or\n",
    "    - trim it, or\n",
    "    - produce a spectrogram of it\n",
    "- Extract some features or segmentations using the onset and beat detection implementations in `librosa`\n",
    "    - Optionally, sonify these features and visualise the effect of this sonification, through the addition of further subplots.\n",
    "- Use `matplotlib` subplots to connect your visual representations of the the original recording and your processed/analysed version of it, in order to tell a story about the relationship between them.\n",
    "\n",
    "### P0.T2.a. @DLEveryFriday\n",
    "\n",
    "Every Friday since January 29, 2021, David Lynch has posted a video message on Twitter celebrating the arrival of the last day of the working week.\n",
    "\n",
    "I've noticed that recently, his performance gets more and more high-pitched and drawn out. We might not think about this is a musical performance, but speech has structure in time and in pitch that can be explored using the tools of music information retrieval.\n",
    "\n",
    "To try and better understand whether this hypothesis could be true, use some combination of visualisation and or analysis with `librosa` (and any other tools you might find useful).\n",
    "\n",
    "You'll need to download these videos before you can analyse them. A Python-based tool called `gallery-dl` is useful for downloading large amounts of web media. So is `youtube-dl` (or its more recent fork, `yt-dlp`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86d9a6af-5962-4b62-8ffd-5ce7fddceaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mdata/twitter/DLEveryFriday/1461732628244176906_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1459186241417760770_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1456641480030932998_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1454107332938457100_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1451563100214280216_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1449023895240159236_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1446485013915181070_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1443951478998278146_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1441407461856927750_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1438873255184642049_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1436343844539355136_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1433808185362632709_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1431271550024622085_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1428727328784408576_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1426196444936122370_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1423668881609175058_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1421122268273512456_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1418592869749862410_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1416058147312128000_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1413511856224817156_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1410978927321964545_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1408439501618298886_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1405905182387544073_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1403362132989726728_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1400831195743670273_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1398296183647477770_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1395751353021091845_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1393220992877613059_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1390684330314321920_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1388144758518951938_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1385612178330357766_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1383075805136293907_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1380536937694511105_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1377998558633340938_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1375463215509999621_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1372920208474714117_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1370396301993644043_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1367862374183677959_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1365324396001439754_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1362790120206852097_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1360253109038153734_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1357828192262832130_1.mp4\u001b[0m\n",
      "\u001b[1;32mdata/twitter/DLEveryFriday/1355280818369949698_1.mp4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!gallery-dl -d data/ https://twitter.com/dleveryfriday?lang=en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc7700-4a81-42db-b98e-d55c1c106879",
   "metadata": {},
   "source": [
    "Even though these are video files, you can still open them using `librosa.load`.\n",
    "\n",
    "You will also need to keep a record of the original time that these videos were created. The filename is the `tweet_id` (status ID) and not a timestamp. You'll have to get these from the file system, either through something like the built-in `os` module ([documentation here](https://docs.python.org/3/library/os.html)) or through clever use of shell invocations and [the way that Jupyter Notebook stores cell outputs](https://stackoverflow.com/questions/27952428/programmatically-get-current-ipython-notebook-cell-output).\n",
    " \n",
    "Load one or two of these into a spectrogram and think about what is involved in detecting the moment where Lynch starts saying \"Friday\". Then, if you can locate this moment in one recording, what might be involved in finding similar segments in the other recordings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02cc5d1-3560-4ad8-9536-8a5b16daa0be",
   "metadata": {},
   "source": [
    "There is a task called voice activity detection (VAD), which you might like to explore. [This might set you in the right direction](https://github.com/wiseman/py-webrtcvad/blob/master/example.py).\n",
    "\n",
    "Once you have found the correct segment in each of the recordings, what are the next steps you might take? Examine `librosa.pitch` for ideas.\n",
    "\n",
    "This is not a straightforward task and I don't expect you to complete it, but I am curious to hear from you how you might begin to address the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ccd41b-d1f2-44c0-bfb2-b6c15196ee64",
   "metadata": {},
   "source": [
    "### P0.T2.a. Write your own onset detector\n",
    "\n",
    "Returning to the section \"Detecting time-series features\" in the Lecture notebook, consider what is involved in writing your own onset detector that works on time-domain representations of sound.\n",
    "\n",
    "Take the results of `librosa.onset.onset_detect` when applied to the `data/clicks.wav` file as your reference or source of ground truth.\n",
    "\n",
    "Write your own function (either wrapping `scipy.signal.find_peaks` or any other peak detection package you might find online, or writing your own from scratch) that returns an array of time values, one per onset.\n",
    "\n",
    "Design a scoring function that will rate the success of your onset detector, by comparing its results to the reference/ground truth. Some ideas:\n",
    "    - the scoring function might be as simple as counting the number of onsets detected and comparing them to each other\n",
    "    - you will have to allow for some tolerance (\n",
    "\n",
    "### P0.T2.c. Text analysis\n",
    "\n",
    "In this exercise you will work with a messier dataset about music, two dumps of Reddit comments (dating from January 2017) from different subreddits corresponding to two (rather different) genres of media: /r/asmr and /r/vaporwave.\n",
    "\n",
    "- [data/reddit-comments/asmr2017-01.zip](http://www.columbia.edu/~epb2125/techniques/data/reddit-comments/asmr2017-01.zip)\n",
    "- [data/reddit-comments/vaporwave2017-01.zip](http://www.columbia.edu/~epb2125/techniques/data/reddit-comments/vaporwave2017-01.zip)\n",
    "\n",
    "Exploring these datasets in whatever way you like with the help of Python, characterize three differences and three similarities between these two online communities, at least as they are represented in these comments.\n",
    "\n",
    "You might find the packages `TextBlob` and/or `spaCy` useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15862d0e-2b93-4159-b7c1-83089cfb3c8a",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "### Useful Python packages\n",
    "\n",
    "- `librosa`\n",
    "- `pretty-midi`\n",
    "- `essentia`\n",
    "- `music21`\n",
    "- `madmom`\n",
    "- `amen`\n",
    "\n",
    "### Non-Python tools\n",
    "\n",
    "- essentia\n",
    "- Tone.js\n",
    "- Humdrum toolkit\n",
    "\n",
    "### Learning more\n",
    "\n",
    "- A good place to start to get a quick sense for what is possible is [musicinformationretrieval.com]\n",
    "- Meinard Müller, _Fundamentals of Music Processing: Using Python and Jupyter Notebooks_. 2nd edition, 495 p., hardcover. Springer, 2021.\n",
    "    - Excellent [online Jupyter notebooks](https://www.audiolabs-erlangen.de/resources/MIR/FMP/C0/C0.html) support this text\n",
    "- The `librosa` documentation is full of [useful and non-trivial examples](https://librosa.org/librosa_gallery/), but more than that, its code is very readable. It is useful for understanding how classic techniques in the field should be implemented.\n",
    "- [Audio Signal Processing for Music Applications](https://www.coursera.org/learn/audio-signal-processing), a MOOC on Coursera.org by Xavier Serra and Julius O. Smith III is quite good too.\n",
    "\n",
    "### More extensive lists of resoures\n",
    "\n",
    "- https://github.com/ciconia/awesome-music"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
